---
title: 'Size: L2'
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(formatR.arrow=TRUE, width=68, digits=5,show.signif.stars = TRUE)
library(ggplot2)
library(party)
library(dplyr)
library(lme4)
#library(lmerTest)
#library(lmtest)
library(stringr)
#library(merTools)
library(latticeExtra)
```


## Data analysis

We load the data and remove the cases with NA values.
```{r data, echo=FALSE}
load("size.RData")
DLM<-Size
```

We have `r nlevels(DLM$Name)` subjects for a total of `r dim(DLM)[1]` observations. 

```{r naomit, echo=FALSE}
DLM<-na.omit(DLM)
DLM$Name<-factor(DLM$Name)
```
After removal of entries with missing data due to wrong answers, we have `r nlevels(DLM$Name)` subjects and `r dim(DLM)[1]` observations left.

```{r dataoverview, eval=FALSE, echo=FALSE}
# Let's have a glimpse at the data:
# tbl_df(DLM)
glimpse(DLM)
```

We consider the following independent variables:

1. `LEAYRS` a numerical variable with values ranging from 1 to 16. Learning in years.
2. `POST1` a percentage scaled to lay between 0 and 10. It indicates the post test proficency. 
3. `PRE` a percentage scaled to lay between 0 and 10. It indicates the previous knowledge.
<!--- `RPV`  a numerical variable with values ranging from 1 to 4.5.-->
<!--- `AMGE`  a numerical variable with values ranging from 1 to 5.-->
4. `AMSP`  a numerical variable with values ranging from 1 to 5.
5. `HRSD`  a numerical variable with values ranging from 0 to 11.5. L2 use in hours per day.

We rescaled some of these variables to be on similar scales. We treat these as fixed factors under study. In addition we have the random factors described earlier. The same modelling set up applies here.

The basic model is: 
`lmm <- lmer(log(Time) ~ type + LEAYRS + (PRE + POST1)^2 + AMSP + HRSD + POST1*HRSD +  (1 | List:Name) + (1 | List:type:Order), data = DLM)`

```{r basicmodel}
lmm <- lmer(log(Time) ~  type + LEAYRS + (PRE + POST1)^2 + AMSP + HRSD + POST1*HRSD + (1 | List:Name) + (1 | List:type:Order), data = DLM, REML=FALSE)
#summary(lmm)
```

We use a  manual, step-forward procedure with likelihood ratio test to see which of the fixed effects are significant.


```{r mixedmodels2, warning=TRUE}
lmm.0 <- lmer(log(Time) ~  (1 | List:Name) + (1 | List:type:Order), data = DLM)

lmm.1 <- update(lmm.0, .~. + type)
anova(lmm.0,lmm.1)

lmm.2 <- update(lmm.0, .~.+LEAYRS)
anova(lmm.0,lmm.2)

lmm.3 <- update(lmm.0, .~. + POST1) 
anova(lmm.0,lmm.3)

lmm.3 <- update(lmm.0, .~. + PRE) 
anova(lmm.0,lmm.3)

lmm.3 <- update(lmm.0, .~. + POST1) 
anova(lmm.0,lmm.3)

lmm.3 <- update(lmm.0, .~. + PRE*POST1) 
anova(lmm.0,lmm.3)

lmm.4 <- update(lmm.0, .~. + AMSP)
anova(lmm.0,lmm.4)

lmm.5 <- update(lmm.0, .~. + HRSD)
anova(lmm.0,lmm.5)
```

We conclude that only `AMSP` has a significant effect at a 0.05 level while the type has a significant effect at a level of 0.1.


An automatic, step-backward procedure from the package lmerTest starting from a model that includes all second order fixed factor intereactions lead to a different conclusion: the factors AMSP, POST1, HRSD and the interaction between these last two are significant.


```{r mixedmodels4, echo=TRUE, eval=TRUE, warning=FALSE, message=FALSE}
require(lmerTest)
lmm.6 <- lmer(log(Time) ~ (type + LEAYRS + POST1 + PRE + AMSP + HRSD)^2 + (1 | List:Name) + (1 | List:type:Order), data = DLM)
ft<-step(lmm.6)
ft
summary(ft$model)
lmm<-ft$model
```

Finally, Analysis of Variance Table of type III  with  Satterthwaite 
approximation for degrees of freedom gives produces yet another different analysis. It is reported at the end of this document.


All three analysis indicate however that  `AMSP`  is significant. 


```{r confintstd, eval=FALSE, echo=FALSE}
confint(lmm,method="Wald")
confint(lmm,method="boot")
```


The figures show random  and the fixed effects. Again the subject effects are significant. We back transformed the fixed effects in linear scale and added 0.95-confidence level bands. It is evident the reduction in reaction time as `AMSP` increases. The `HRSD` values do not seem to have a considerable impact while `PRE` and `POST1` interactions are relevant but only among subjects with low `POST1`. Finally, `HRSD` and `POST1` interactions are depicted.

```{r randomeff, height=4, width=6, echo=FALSE}
#plotREsim(REsim(lmm, n.sims = 100), stat = 'median', sd = TRUE)
source("lib.R")
randeff.plot2(lmm)
```

```{r fixedeff, height=4, width=6, echo=FALSE}
require(effects)
plot(effects::Effect(c("POST1"), lmm, transformation=list(link=log, inverse=exp)),cex=1,width=0,lwd=1,ylab="milliseconds",main="", bg="grey50",fg="black",alternating=FALSE,par.settings = ggplot2like(),lines.title=0,between=list(x=1),colors=c("grey35","black")) 
plot(effects::Effect(c("AMSP"), lmm, transformation=list(link=log, inverse=exp)),cex=1,width=0,lwd=1,ylab="milliseconds",main="", bg="grey50",fg="black",alternating=FALSE,par.settings = ggplot2like(),lines.title=0,between=list(x=1),colors=c("grey35","black")) 
plot(effects::Effect(c("HRSD"), lmm, transformation=list(link=log, inverse=exp)),cex=1,width=0,lwd=1,ylab="milliseconds",main="", bg="grey50",fg="black",alternating=FALSE,par.settings = ggplot2like(),lines.title=0,between=list(x=1),colors=c("grey35","black")) 
#plot(effects::Effect(c("PRE","POST1"), lmm, transformation=list(link=log, inverse=exp)),cex=1,width=0,lwd=1,ylab="milliseconds",main="", bg="grey50",fg="black",alternating=FALSE,par.settings = ggplot2like(),lines.title=0,between=list(x=1),colors=c("grey35","black")) 
plot(effects::Effect(c("HRSD","POST1"), lmm, transformation=list(link=log, inverse=exp)),cex=1,width=0,lwd=1,ylab="milliseconds",main="", bg="grey50",fg="black",alternating=FALSE,par.settings = ggplot2like(),lines.title=0,between=list(x=1),colors=c("grey35","black"))
#require(merTools)
#plotFEsim(FEsim(lmm, n.sims = 100), level = 0.9, stat = 'median', intercept = FALSE)
```



## Diagnostic plots

```{r plotlmr, fig.height=8}

par(mfrow=c(3,2))
# plot(lm4,which=1:4)

plot(fitted(lmm, type = "response"), residuals(lmm, type = "response"),
     main = "Conditional residuals", xlab = "Predicted", ylab = "Residuals")

res <- residuals(lmm, type = "response")
qqnorm(res, main = "Conditional residuals, QQplot")
qqline(res)

#lm.0 <- lm(log(Time) ~ (type + LEAYRS + (PRE + POST1)^2 + AMSP + HRSD + POST1*HRSD ), data = DLM)
lm.0 <- lm(log(Time) ~ (POST1 + AMSP + HRSD + POST1*HRSD ), data = DLM)
x <- model.matrix(lm.0)
pred <- x %*% fixef(lmm)
res <- DLM$Time - pred
plot(pred, res, main = "Marginal residuals", xlab = "Predicted", ylab = "Residuals")
qqnorm(res, main = "Marginal residuals, QQplot")
qqline(res)

```

```{r plot1, fig.width=3, echo=FALSE, eval=FALSE}
plot(lmm,type=c("p","smooth"))
plot(lmm,sqrt(abs(resid(.))) ~ fitted(.), type=c("p","smooth"))
qqmath(lmm,id=0.005)
# package HLMdiag influence.ME
```


The joint qqplot looks normal. The marginal looks less nice. 


## Anova Table with Satterwhite 

```{r anova}
require(lmerTest)
lmm <- lmer(log(Time) ~  type + LEAYRS + (PRE + POST1)^2 + AMSP + HRSD + POST1*HRSD + (1 | List:Name) + (1 | List:type:Order), data = DLM, REML=FALSE)
anova(lmm)
summary(lmm)
```
