---
title: 'Orientation: 75% POST1 FILTERED L2'
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(formatR.arrow=TRUE, width=68, digits=5,show.signif.stars = TRUE)
library(ggplot2)
library(party)
library(dplyr)
library(lme4)
#library(lmerTest)
#library(lmtest)
library(stringr)
#library(merTools)
library(latticeExtra)
```

## Data analysis

We load the data and remove the cases with NA values.
```{r data, echo=FALSE}
load("orientation.RData")
DLM<-Orientation
```

We have `r nlevels(DLM$Name)` subjects for a total of `r dim(DLM)[1]` observations. 

```{r naomit, echo=FALSE}
DLM <- DLM %>% filter(POST1>7.5) %>% filter(POST2>7.5)
DLM<-na.omit(DLM)
DLM$Name<-factor(DLM$Name)
```

After removal of subjects with POST1 and POST2 <75% and entries with missing data due to wrong answers, we have `r nlevels(DLM$Name)` subjects and `r dim(DLM)[1]` observations left.

```{r dataoverview, eval=FALSE, echo=FALSE}
# Let's have a glimpse at the data:
# tbl_df(DLM)
glimpse(DLM)
```

<!--We removed the subjects that had `POST1` or `POST2` smaller than 75%. -->

We consider the following independent variables:
- `LEAYRS` a numerical variable with values ranging from 1 to 16. Learning in years.
- `LEA` a percentage scaled to lay between 0 and 10. It indicates the novelty of target construction, measured by subtracting pretest score from posttestscore (POST1-PRE). This value indicates the previous knowledge of construction.
<!--- `RPV`  a numerical variable with values ranging from 1 to 4.5.-->
<!--- `AMGE`  a numerical variable with values ranging from 1 to 5.-->
- `AMSP`  a numerical variable with values ranging from 1 to 5.
- `HRSD`  a numerical variable with values ranging from 0 to 11.5. L2 use in hours per day.

We rescaled some of these variables to be on similar scales. We treat these as fixed factors under study. In addition we have the random factors described earlier. The same modelling set up applies here. 

Our base model is the following
`lmm <- lmer(log(Time) ~ type + LEAYRS + LEA + AMSP + HRSD + (1 | List:Name) + (1 | List:type:Order), data = DLM)`

```{r basicmodel}
lmm <- lmer(log(Time) ~  type + LEAYRS + LEA + AMSP + HRSD + (1 | List:Name) + (1 | List:type:Order), data = DLM, REML=FALSE)
summary(lmm)
```

We use a  manual, step-forward procedure with likelihood ratio test to see which of the fixed effects are significant.


```{r mixedmodels2, warning=TRUE}
lmm.0 <- lmer(log(Time) ~  (1 | List:Name) + (1 | List:type:Order), data = DLM)

lmm.1 <- update(lmm.0, .~. + type)
anova(lmm.0,lmm.1)

lmm.2 <- update(lmm.0, .~.+LEAYRS)
anova(lmm.0,lmm.2)

lmm.3 <- update(lmm.0, .~. + LEA) 
anova(lmm.0,lmm.3)

lmm.4 <- update(lmm.0, .~. + AMSP)
anova(lmm.0,lmm.4)

lmm.5 <- update(lmm.0, .~. + HRSD)
anova(lmm.0,lmm.5)
```

We conclude that `LEAYRS` is significant at a 0.05 significance level, while `PRE` is significant at a 0.1 significance level.

An automatic, step-backward procedure from the package lmerTest starting from a model that includes all second order fixed factor intereactions lead to a similar conclusion: the factors `type`, `LEA`, `AMSP`, `HRSD` are not significant while  `LEAYRS` is the only significant factor. An ANOVA, shown below, confirms this analysis with `LEAYRS` as the only significant factor.



```{r mixedmodels4, echo=TRUE, eval=TRUE, warning=FALSE}
require(lmerTest)
lmm.6 <- lmer(log(Time) ~ (type + LEAYRS + LEA + AMSP + HRSD)^2 + (1 | List:Name) + (1 | List:type:Order), data = DLM)
ft<-step(lmm.6)
ft
```


```{r confintstd, eval=FALSE, echo=FALSE}
confint(lmm,method="Wald")
confint(lmm,method="boot")
```


The figures show random and the fixed effects. The random effects show that the different subjects imply a significantly different intercept. In the plot of the fixed effects, we back transformed the effects in linear scale and added 0.95-confidence level bands. It is evident the reduction in reaction time as learning years increase. As far as proficency is concerned, we see that increasing `LEA` reaction time decreases. However this effect is not statistically significant.



```{r randomeff, height=4, width=6, echo=FALSE}
#plotREsim(REsim(lmm, n.sims = 100), stat = 'median', sd = TRUE)
source("lib.R")
randeff.plot2(lmm)
```

```{r fixedeff, height=4, width=6, echo=FALSE}
#require(merTools)
#plotFEsim(FEsim(lmm, n.sims = 100), level = 0.9, stat = 'median', intercept = FALSE)
require(effects)
plot(effects::Effect(c("LEAYRS"), lmm, transformation=list(link=log, inverse=exp)),cex=1,width=0,lwd=1,ylab="milliseconds",xlab="LEAYRS",main="", bg="grey50",fg="black",alternating=FALSE,par.settings = ggplot2like(),lines.title=0,between=list(x=1),colors=c("grey35","black")) 
plot(effects::Effect(c("LEA"), lmm, transformation=list(link=log, inverse=exp)),cex=1,width=0,lwd=1,ylab="milliseconds",main="", bg="grey50",fg="black",alternating=FALSE,par.settings = ggplot2like(),lines.title=0,between=list(x=1),colors=c("grey35","black")) 
hist(DLM$POST1)
```





## Diagnostic plots

```{r plotlmr, fig.height=8}

par(mfrow=c(3,2))
# plot(lm4,which=1:4)

plot(fitted(lmm, type = "response"), residuals(lmm, type = "response"),
     main = "Conditional residuals", xlab = "Predicted", ylab = "Residuals")

res <- residuals(lmm, type = "response")
qqnorm(res, main = "Conditional residuals, QQplot")
qqline(res)

lm.0 <- lm(log(Time) ~ ( type + LEAYRS + LEA + AMSP + HRSD ), data = DLM)
x <- model.matrix(lm.0)
pred <- x %*% fixef(lmm)
res <- DLM$Time - pred
plot(pred, res, main = "Marginal residuals", xlab = "Predicted", ylab = "Residuals")
qqnorm(res, main = "Marginal residuals, QQplot")
qqline(res)

```


```{r plot1, fig.width=3, echo=FALSE, eval=FALSE}
plot(lmm,type=c("p","smooth"))
plot(lmm,sqrt(abs(resid(.))) ~ fitted(.), type=c("p","smooth"))
qqmath(lmm,id=0.005)
# package HLMdiag influence.ME
```


The joint qqplot looks normal. The marginal looks less nice. 



## Anova Table with Satterwhite 

```{r anova}
require(lmerTest)
lmm <- lmer(log(Time) ~  type + LEAYRS + LEA + AMSP + HRSD + (1 | List:Name) + (1 | List:type:Order), data = DLM, REML=FALSE)
anova(lmm)
summary(lmm)
```


